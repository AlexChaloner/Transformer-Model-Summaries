---
layout: default
---

# (XLNET) XLNET: Generalized Autoregressize Pretraining for Language Understanding

Arxiv Link: https://arxiv.org/pdf/1906.08237.pdf

Papers with Code link: https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining


> Yang Z, Dai Z, Yang Y, Carbonell J, Salakhutdinov R, Le QV. Xlnet: Generalized autoregressive pretraining for language understanding. arXiv preprint arXiv:1906.08237. 2019 Jun 19.


## Summary

Finds that Next Sentence Prediction (NSP) from [BERT] does not necessarily improve performance.
